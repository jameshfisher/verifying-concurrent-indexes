\subsubsection{Reasoning about concurrent systems}

\paragraph{Models of concurrent systems}

CSP (Communicating Sequential Processes).  Hoare, 1978.
CCS (Calculus of Communicating Systems).  Milner, 1980.
ACP (Algebra of Communicating Processes).  Bergstra/Klop, 1982.
pi-calculus.  Milner, 1992.  From: CCS.
PEPA (Performance Evaluation Process Algebra).  From: CSP, CCS.
Ambient Calculus.  Cardelli/Gordon, 1998.


\paragraph{Separation logic + concurrency}

These have in common a model of interaction as message-passing, not shared variables.
But real-world concurrent systems operate on shared data.
Separation logic is a good candidate for reasoning about these systems, because all sharing is done by the heap.
So how can we extend separation logic to deal with concurrent heap access?


\paragraph{Deny-guarantee}

Most models of concurrency use parallel composition.
But this is not how real-world programs are structured; they use fork() and join().
In parallel composition, the lifetime of each thread is ‘statically scoped’.
Real-world threading is dynamic; join() may never be called!
Dodds et al. propose deny-guarantee, an evolution of rely-guarantee reasoning.


\paragraph{CAP}

The core idea of CAP is the use of concurrent sep logic to define black-box behavior,
  allowing correct black-box composition without knowledge of the details.
Again, it separates specification from implementation.
This allows proofs to be made at high levels without concern for implementation---a requirement for scalable reasoning.
Higher-level proofs can themselves be composed in the same way.
The given motivating example is a lock.
The specification of a lock is given in three Hoare triples.
These are intuitive and allow someone to, for example, verify a tree-update algorithm without concern for the particular locking implementation.
Given that the specification is abstract, do we need definition in order to use it, or in order to verify an implementation?
What does the predicate Locked(l) mean?
The answer is a set of abstract predicate axioms.
The key characteristic of a lock is that it can’t be locked by two threads,
  which is captured as
  Locked(l) * Locked(l) ↔ false.
The predicates can be given more precise meanings in terms of shared regions and permissions.
We may state Locked(l) as:
  \enquote{there exists a region of memory r such that l points to the value 1 (locked), and the exclusive permission to UNLOCK region r is held.}
The definitions of these predicates should ensure \enquote{self-stability}---that is,
  if a thread has some predicate,
  then no actions taken by environment may change the validity of that predicate.
Example: the predicate isLock(l) can be changed neither by a lock(l) action nor an unlock(l) action.
(How do we model destroying the lock?)
We then add two more assertions to the specification that state isLock and Locked are stable.
(Why do we need this?
What assertions are not self-stable?
What is the use of these?
Isn’t an unstable predicate useless---it can’t be considered when writing the postcondition of a command?)
